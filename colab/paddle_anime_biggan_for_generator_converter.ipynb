{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "paddle anime biggan for generator converter.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1zkKig_RPbdca89RENcmUgticG9SiGuvD",
      "authorship_tag": "ABX9TyOM1bsrst8W7jwuQ4F2ROG4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HighCWu/2018Summer/blob/master/colab/paddle_anime_biggan_for_generator_converter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaUYHr7V0tlG"
      },
      "source": [
        "## Save weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnZqvQSZYhY4"
      },
      "source": [
        "!cp drive/My\\ Drive/anime-biggan-256px-run39-607250 ./ -r"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKdD7uz59HJ3"
      },
      "source": [
        "import os\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        " \n",
        "import tensorflow_hub as hub\n",
        " \n",
        "module_path = os.path.join('anime-biggan-256px-run39-607250', \"tfhub\")\n",
        "tf.reset_default_graph()\n",
        "module = hub.Module(module_path)\n",
        "print('Loaded BigGAN module from:', module_path)\n",
        " \n",
        "initializer = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(initializer)\n",
        " \n",
        "batch_size = 4\n",
        "use_ema = True\n",
        "z = tf.random.normal(shape=[batch_size, 140],stddev=1.0,seed=0)  # noise sample\n",
        "labels = tf.random.uniform([batch_size], maxval=1000, dtype=tf.int32, seed=0)\n",
        "inputs = dict(z=z, labels=labels)\n",
        " \n",
        "samples = module(inputs, as_dict=True)['generated']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qX6oSq661Sq"
      },
      "source": [
        "for tensor in [tensor for op in sess.graph.get_operations() for tensor in op.values()]:\n",
        "    if 'module_apply_default/generator' + ('_1' if use_ema else '') in tensor.name:\n",
        "        print(tensor.name, tensor.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psuukclucWZL"
      },
      "source": [
        "var_list = []\n",
        "for var in tf.global_variables():\n",
        "    if 'discriminator' not in var.name:\n",
        "        val = sess.run(var)\n",
        "        if '/ExponentialMovingAverage' in var.name and use_ema:\n",
        "            name = ''.join(var.name.split('/ExponentialMovingAverage'))\n",
        "            for i, weights in enumerate(var_list):\n",
        "                if weights[0] == name:\n",
        "                    weights[1] = val\n",
        "        else:\n",
        "            var_list.append([var.name, val])\n",
        " \n",
        "for weights in var_list:\n",
        "  print(weights[0], weights[1].shape)\n",
        " \n",
        "import pickle\n",
        "f = open('tf_generator.pkl', 'wb')\n",
        "pickle.dump(var_list, f)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCeRAAolojmm"
      },
      "source": [
        "tensors_name_con = [\n",
        "    'fc_reshaped:0', 'embed_y/MatMul:0', 'accu/truediv:0', 'accu/truediv_1:0', 'batchnorm/add_1:0', \n",
        "    'condition/gamma/MatMul_4:0', 'condition/beta/MatMul_4:0', 'condition/add:0', \n",
        "    'unpool:0', 'up_conv1/Reshape/ReadVariableOp:0', 'up_conv1/Reshape_1:0', 'conv1/add:0', 'conv2/add:0', 'conv_shortcut/add:0', \n",
        "    'conv2d_theta/Conv2D:0', 'conv2d_phi/Conv2D:0', 'conv2d_g/Conv2D:0', 'conv2d_attn_g/Conv2D:0',\n",
        "    'final_norm/add:0', 'final_conv/add:0'\n",
        "]\n",
        "import collections\n",
        "tensor_dict = collections.OrderedDict()\n",
        "tensor_dict['z'] = z\n",
        "tensor_dict['labels'] = labels\n",
        "for tensor in [tensor for op in sess.graph.get_operations() for tensor in op.values()]:\n",
        "    if 'module_apply_default/generator' + ('_1' if use_ema else '') in tensor.name:\n",
        "        for name_con in tensors_name_con:\n",
        "            if name_con in tensor.name:\n",
        "                tensor_dict[tensor.name] = tensor\n",
        "                break\n",
        "tensor_dict['samples'] = samples\n",
        " \n",
        "# for name, tensor in tensor_dict.items():\n",
        "#     print(name, tensor)\n",
        " \n",
        "ret = sess.run(tensor_dict)\n",
        " \n",
        "for name, value in ret.items():\n",
        "    print(name, value.shape)\n",
        " \n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "display(Image.fromarray(np.uint8(ret['samples'][0].clip(0,1)*255)))\n",
        " \n",
        "import pickle\n",
        "f = open('tf_tensor_samples.pkl', 'wb')\n",
        "pickle.dump(ret, f)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3eagKqD0xP7"
      },
      "source": [
        "## Convert weights\n",
        "You may want to restart the kernel to release gpu memory after generating some samples use TF."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlxRCG7jS_Tu"
      },
      "source": [
        "!pip install paddlepaddle-gpu==1.8.4.post107"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHtuKUzN1HwD"
      },
      "source": [
        "import numpy as np\n",
        "import paddle.fluid as fluid\n",
        "from paddle.fluid import layers, dygraph as dg\n",
        "from paddle.fluid.initializer import Normal, Constant, Uniform\n",
        " \n",
        "import collections\n",
        "tensors_name_con = [ 'z','labels',\n",
        "    'fc_reshaped:0', 'embed_y/MatMul:0', 'accu/truediv:0', 'accu/truediv_1:0', 'batchnorm/add_1:0', \n",
        "    'condition/gamma/MatMul_4:0', 'condition/beta/MatMul_4:0', 'condition/add:0', \n",
        "    'unpool:0', 'up_conv1/Reshape/ReadVariableOp:0', 'up_conv1/Reshape_1:0', 'conv1/add:0', 'conv2/add:0', 'conv_shortcut/add:0', \n",
        "    'conv2d_theta/Conv2D:0', 'conv2d_phi/Conv2D:0', 'conv2d_g/Conv2D:0', 'conv2d_attn_g/Conv2D:0',\n",
        "    'final_norm/add:0', 'final_conv/add:0',\n",
        "    'samples'\n",
        "]\n",
        "gt = collections.OrderedDict()\n",
        "for n in tensors_name_con:\n",
        "    gt[n] = []\n",
        " \n",
        "def unpool(value):\n",
        "    \"\"\"Unpooling operation.\n",
        "    N-dimensional version of the unpooling operation from\n",
        "    https://www.robots.ox.ac.uk/~vgg/rg/papers/Dosovitskiy_Learning_to_Generate_2015_CVPR_paper.pdf\n",
        "    Taken from: https://github.com/tensorflow/tensorflow/issues/2169\n",
        "    Args:\n",
        "        value: a Tensor of shape [b, d0, d1, ..., dn, ch]\n",
        "        name: name of the op\n",
        "    Returns:\n",
        "        A Tensor of shape [b, 2*d0, 2*d1, ..., 2*dn, ch]\n",
        "    \"\"\"\n",
        "    value = layers.transpose(value, [0,2,3,1])\n",
        "    sh = value.shape\n",
        "    dim = len(sh[1:-1])\n",
        "    out = (layers.reshape(value, [-1] + sh[-dim:]))\n",
        "    for i in range(dim, 0, -1):\n",
        "        out = layers.concat([out, layers.zeros_like(out)], i)\n",
        "    out_size = [-1] + [s * 2 for s in sh[1:-1]] + [sh[-1]]\n",
        "    out = layers.reshape(out, out_size)\n",
        "    out = layers.transpose(out, [0,3,1,2])\n",
        "    return out\n",
        " \n",
        "class ReLU(dg.Layer):\n",
        "    def forward(self, x):\n",
        "        return layers.relu(x)\n",
        "    \n",
        " \n",
        "class SoftMax(dg.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "        self.kwargs = kwargs\n",
        "  \n",
        "    def forward(self, x):\n",
        "        return layers.softmax(x, **self.kwargs)\n",
        " \n",
        " \n",
        "class BatchNorm(dg.BatchNorm):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        if 'affine' in kwargs:\n",
        "            affine = kwargs.pop('affine')\n",
        "        else:\n",
        "            affine = True\n",
        "        super().__init__(*args, **kwargs)\n",
        "        if not affine:\n",
        "            weight = (self.weight * 0 + 1).detach()\n",
        "            bias = (self.bias * 0).detach()\n",
        "            del self._parameters['bias']\n",
        "            del self._parameters['weight']\n",
        "            self.weight = weight\n",
        "            self.bias = bias\n",
        "        self.initialized = False\n",
        "        self.accumulating = False\n",
        "        self.accumulated_mean = self.create_parameter(shape=[args[0]], default_initializer=Constant(0.0))\n",
        "        self.accumulated_var = self.create_parameter(shape=[args[0]], default_initializer=Constant(0.0))\n",
        "        self.accumulated_counter = self.create_parameter(shape=[1], default_initializer=Constant(1e-12))\n",
        "        self.accumulated_mean.trainable = False\n",
        "        self.accumulated_var.trainable = False\n",
        "        self.accumulated_counter.trainable = False\n",
        "        self.affine = affine\n",
        " \n",
        "    def forward(self, inputs, *args, **kwargs):\n",
        "        if not self.initialized:\n",
        "            self.check_accumulation()\n",
        "            self.set_initialized(True)\n",
        "        if self.accumulating:\n",
        "            self.eval()\n",
        "            with dg.no_grad():\n",
        "                axes = [0] + ([] if len(inputs.shape) == 2 else list(range(2,len(inputs.shape))))\n",
        "                _mean = layers.reduce_mean(inputs, axes, keep_dim=True)\n",
        "                mean = layers.reduce_mean(inputs, axes, keep_dim=False)\n",
        "                var = layers.reduce_mean((inputs-_mean)**2, axes)\n",
        "                self.accumulated_mean.set_value(self.accumulated_mean + mean)\n",
        "                self.accumulated_var.set_value(self.accumulated_var + var)\n",
        "                self.accumulated_counter.set_value(self.accumulated_counter + 1)\n",
        "                _mean = self._mean*1.0\n",
        "                _variance = self.variance*1.0\n",
        "                self._mean.set_value(self.accumulated_mean / self.accumulated_counter)\n",
        "                self._variance.set_value(self.accumulated_var / self.accumulated_counter)\n",
        "                out = super().forward(inputs, *args, **kwargs)\n",
        "                self._mean.set_value(_mean)\n",
        "                self._variance.set_value(_variance)\n",
        "                return out\n",
        "        gt['accu/truediv:0'].append(self._mean)\n",
        "        gt['accu/truediv_1:0'].append(self._variance)\n",
        "        out = super().forward(inputs, *args, **kwargs)\n",
        "        gt['batchnorm/add_1:0'].append(layers.transpose(out,[0,2,3,1]))\n",
        "        return out\n",
        " \n",
        "    def check_accumulation(self):\n",
        "        if self.accumulated_counter.numpy().mean() > 1-1e-12:\n",
        "            self._mean.set_value(self.accumulated_mean / self.accumulated_counter)\n",
        "            self._variance.set_value(self.accumulated_var / self.accumulated_counter)\n",
        "            return True\n",
        "        return False\n",
        " \n",
        "    def clear_accumulated(self):\n",
        "        self.accumulated_mean.set_value(self.accumulated_mean*0.0)\n",
        "        self.accumulated_var.set_value(self.accumulated_var*0.0)\n",
        "        self.accumulated_counter.set_value(self.accumulated_counter*0.0+1e-2)\n",
        " \n",
        "    def set_accumulating(self, status=True):\n",
        "        if status:\n",
        "            self.accumulating = True\n",
        "        else:\n",
        "            self.accumulating = False\n",
        " \n",
        "    def set_initialized(self, status=False):\n",
        "        if not status:\n",
        "            self.initialized = False\n",
        "        else:\n",
        "            self.initialized = True\n",
        "      \n",
        "    def train(self):\n",
        "        super().train()\n",
        "        if self.affine:\n",
        "            self.weight.stop_gradient = False\n",
        "            self.bias.stop_gradient = False\n",
        "        else:\n",
        "            self.weight.stop_gradient = True\n",
        "            self.bias.stop_gradient = True\n",
        "        self._use_global_stats = False\n",
        "    \n",
        "    def eval(self):\n",
        "        super().eval()\n",
        "        self.weight.stop_gradient = True\n",
        "        self.bias.stop_gradient = True\n",
        "        self._use_global_stats = True\n",
        " \n",
        " \n",
        "class SpectralNorm(dg.Layer):\n",
        "    def __init__(self, module, name='weight', power_iterations=2):\n",
        "        super().__init__()\n",
        "        self.module = module\n",
        "        self.name = name\n",
        "        self.power_iterations = power_iterations\n",
        "        if not self._made_params():\n",
        "            self._make_params()\n",
        " \n",
        "    def _update_u(self):\n",
        "        w = self.weight\n",
        "        u = self.weight_u\n",
        " \n",
        "        if len(w.shape) == 4:\n",
        "            _w = layers.transpose(w, [2,3,1,0])\n",
        "            _w_t_shape = _w.shape\n",
        "            _w = layers.reshape(_w, [-1, _w.shape[-1]])\n",
        "        else:\n",
        "            _w = layers.reshape(w, [-1, w.shape[-1]])\n",
        "            _w = layers.reshape(_w, [-1, _w.shape[-1]])\n",
        "        singular_value = \"left\" if _w.shape[0] <= _w.shape[1] else \"right\"\n",
        "        norm_dim = 0 if _w.shape[0] <= _w.shape[1] else 1\n",
        "        for _ in range(self.power_iterations):\n",
        "            if singular_value == \"left\":\n",
        "                v = layers.l2_normalize(layers.matmul(_w, u, transpose_x=True), axis=norm_dim)\n",
        "                u = layers.l2_normalize(layers.matmul(_w, v), axis=norm_dim)\n",
        "            else:\n",
        "                v = layers.l2_normalize(layers.matmul(u, _w, transpose_y=True), axis=norm_dim)\n",
        "                u = layers.l2_normalize(layers.matmul(v, _w), axis=norm_dim)\n",
        " \n",
        "        if singular_value == \"left\":\n",
        "            sigma = layers.matmul(layers.matmul(u, _w, transpose_x=True), v)\n",
        "        else:\n",
        "            sigma = layers.matmul(layers.matmul(v, _w), u, transpose_y=True)\n",
        "        _w = w / sigma\n",
        "        setattr(self.module, self.name, _w)\n",
        "        self.weight_u.set_value(u)\n",
        " \n",
        "    def _made_params(self):\n",
        "        try:\n",
        "            self.weight\n",
        "            self.weight_u\n",
        "            return True\n",
        "        except AttributeError:\n",
        "            return False\n",
        " \n",
        "    def _make_params(self):\n",
        "        # paddle linear weight is similar with tf's, and conv weight is similar with pytorch's.\n",
        "        w = getattr(self.module, self.name)\n",
        " \n",
        "        if len(w.shape) == 4:\n",
        "            _w = layers.transpose(w, [2,3,1,0])\n",
        "            _w = layers.reshape(_w, [-1, _w.shape[-1]]) \n",
        "        else:\n",
        "            _w = layers.reshape(w, [-1, w.shape[-1]])\n",
        "        singular_value = \"left\" if _w.shape[0] <= _w.shape[1] else \"right\"\n",
        "        norm_dim = 0 if _w.shape[0] <= _w.shape[1] else 1\n",
        "        u_shape = (_w.shape[0], 1) if singular_value == \"left\" else (1, _w.shape[-1])\n",
        "        \n",
        "        u = self.create_parameter(shape=u_shape, default_initializer=Normal(0, 1))\n",
        "        u.stop_gradient = True\n",
        "        u.set_value(layers.l2_normalize(u, axis=norm_dim))\n",
        " \n",
        "        del self.module._parameters[self.name]\n",
        "        self.add_parameter(\"weight\", w)\n",
        "        self.add_parameter(\"weight_u\", u)\n",
        " \n",
        "    def forward(self, *args, **kwargs):\n",
        "        self._update_u()\n",
        "        return self.module.forward(*args, **kwargs)\n",
        "    \n",
        "    \n",
        "class SelfAttention(dg.Layer):\n",
        "    def __init__(self, in_dim, activation=layers.relu):\n",
        "        super().__init__()\n",
        "        self.chanel_in = in_dim\n",
        "        self.activation = activation\n",
        "    \n",
        "        self.theta = SpectralNorm(dg.Conv2D(in_dim, in_dim // 8, 1, bias_attr=False))\n",
        "        self.phi = SpectralNorm(dg.Conv2D(in_dim, in_dim // 8, 1, bias_attr=False))\n",
        "        self.pool = dg.Pool2D(2, 'max', 2)\n",
        "        self.g = SpectralNorm(dg.Conv2D(in_dim, in_dim // 2, 1, bias_attr=False))\n",
        "        self.o_conv = SpectralNorm(dg.Conv2D(in_dim // 2, in_dim, 1, bias_attr=False))\n",
        "        self.gamma = self.create_parameter([1,], default_initializer=Constant(0.0))\n",
        "    \n",
        "        self.softmax = SoftMax(axis=-1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        m_batchsize, C, width, height = x.shape\n",
        "        N = height * width\n",
        "    \n",
        "        theta = self.theta(x)\n",
        "        gt['conv2d_theta/Conv2D:0'].append(layers.transpose(theta,[0,2,3,1]))\n",
        "        phi = self.phi(x)\n",
        "        gt['conv2d_phi/Conv2D:0'].append(layers.transpose(phi,[0,2,3,1]))\n",
        "        phi = self.pool(phi)\n",
        "        phi = layers.reshape(phi,(m_batchsize, -1, N // 4))\n",
        "        theta = layers.reshape(theta,(m_batchsize, -1, N))\n",
        "        theta = layers.transpose(theta,(0, 2, 1))\n",
        "        attention = self.softmax(layers.bmm(theta, phi))\n",
        "        g = self.g(x)\n",
        "        gt['conv2d_g/Conv2D:0'].append(layers.transpose(g,[0,2,3,1]))\n",
        "        g = layers.reshape(self.pool(g),(m_batchsize, -1, N // 4))\n",
        "        attn_g = layers.reshape(layers.bmm(g, layers.transpose(attention,(0, 2, 1))),(m_batchsize, -1, width, height))\n",
        "        out = self.o_conv(attn_g)\n",
        "        gt['conv2d_attn_g/Conv2D:0'].append(layers.transpose(out,[0,2,3,1]))\n",
        "        return self.gamma * out + x\n",
        " \n",
        " \n",
        "class ConditionalBatchNorm(dg.Layer):\n",
        "    def __init__(self, num_features, num_classes, epsilon=1e-5, momentum=0.1):\n",
        "        super().__init__()\n",
        "        self.bn_in_cond = BatchNorm(num_features, affine=False, epsilon=epsilon, momentum=momentum)\n",
        "        self.gamma_embed = SpectralNorm(dg.Linear(num_classes, num_features, bias_attr=False))\n",
        "        self.beta_embed = SpectralNorm(dg.Linear(num_classes, num_features, bias_attr=False))\n",
        "    \n",
        "    def forward(self, x, y):\n",
        "        out = self.bn_in_cond(x)\n",
        "        gamma = self.gamma_embed(y)\n",
        "        gt['condition/gamma/MatMul_4:0'].append(gamma)\n",
        "        # gamma = gamma + 1\n",
        "        beta = self.beta_embed(y)\n",
        "        gt['condition/beta/MatMul_4:0'].append(beta)\n",
        "        out = layers.reshape(gamma, (0, 0, 1, 1)) * out + layers.reshape(beta, (0, 0, 1, 1))\n",
        "        gt['condition/add:0'].append(layers.transpose(out,[0,2,3,1]))\n",
        "        return out\n",
        " \n",
        " \n",
        "class ResBlock(dg.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channel,\n",
        "        out_channel,\n",
        "        kernel_size=[3, 3],\n",
        "        padding=1,\n",
        "        stride=1,\n",
        "        n_class=None,\n",
        "        conditional=True,\n",
        "        activation=layers.relu,\n",
        "        upsample=True,\n",
        "        downsample=False,\n",
        "        z_dim=128,\n",
        "        use_attention=False\n",
        "    ):\n",
        "        super().__init__()\n",
        "    \n",
        "        if conditional:\n",
        "            self.cond_norm1 = ConditionalBatchNorm(in_channel, z_dim)\n",
        "    \n",
        "        self.conv0 = SpectralNorm(\n",
        "            dg.Conv2D(in_channel, out_channel, kernel_size, stride, padding)\n",
        "        )\n",
        "    \n",
        "        if conditional:\n",
        "            self.cond_norm2 = ConditionalBatchNorm(out_channel, z_dim)\n",
        "    \n",
        "        self.conv1 = SpectralNorm(\n",
        "            dg.Conv2D(out_channel, out_channel, kernel_size, stride, padding)\n",
        "        )\n",
        "    \n",
        "        self.skip_proj = False\n",
        "        if in_channel != out_channel or upsample or downsample:\n",
        "            self.conv_sc = SpectralNorm(dg.Conv2D(in_channel, out_channel, 1, 1, 0))\n",
        "            self.skip_proj = True\n",
        "    \n",
        "        if use_attention:\n",
        "            self.attention = SelfAttention(out_channel)\n",
        "    \n",
        "        self.upsample = upsample\n",
        "        self.downsample = downsample\n",
        "        self.activation = activation\n",
        "        self.conditional = conditional\n",
        "        self.use_attention = use_attention\n",
        "    \n",
        "    def forward(self, input, condition=None):\n",
        "        out = input\n",
        "    \n",
        "        if self.conditional:\n",
        "            out = self.cond_norm1(out, condition)\n",
        "        out = self.activation(out)\n",
        "        if self.upsample:\n",
        "            out = unpool(out) # out = layers.interpolate(out, scale=2)\n",
        "            gt['unpool:0'].append(layers.transpose(out,[0,2,3,1]))\n",
        "        # out = self.conv0(out)\n",
        "        weight = self.conv0.weight\n",
        "        gt['up_conv1/Reshape/ReadVariableOp:0'].append(layers.transpose(weight, [2,3,1,0]))\n",
        "        self.conv0._update_u()\n",
        "        weight_norm = self.conv0.module.weight\n",
        "        gt['up_conv1/Reshape_1:0'].append(layers.transpose(weight_norm, [2,3,1,0]))\n",
        "        out = self.conv0.module(out)\n",
        "        gt['conv1/add:0'].append(layers.transpose(out,[0,2,3,1]))\n",
        "        if self.conditional:\n",
        "            out = self.cond_norm2(out, condition)\n",
        "        out = self.activation(out)\n",
        "        out = self.conv1(out)\n",
        "        gt['conv2/add:0'].append(layers.transpose(out,[0,2,3,1]))\n",
        "    \n",
        "        if self.downsample:\n",
        "            out = layers.pool2d(out, 2, pool_type='avg', pool_stride=2)\n",
        "    \n",
        "        if self.skip_proj:\n",
        "            skip = input\n",
        "            if self.upsample:\n",
        "                skip = unpool(skip) # skip = layers.interpolate(skip, scale=2, resample='NEAREST')\n",
        "            skip = self.conv_sc(skip)\n",
        "            gt['conv_shortcut/add:0'].append(layers.transpose(skip,[0,2,3,1]))\n",
        "            if self.downsample:\n",
        "                skip = layers.pool2d(skip, 2, pool_type='avg', pool_stride=2)\n",
        "        else:\n",
        "            skip = input\n",
        "    \n",
        "        out = out + skip\n",
        "    \n",
        "        if self.use_attention:\n",
        "            out = self.attention(out)\n",
        "    \n",
        "        return out\n",
        " \n",
        " \n",
        "class Generator(dg.Layer):\n",
        "    def __init__(self, code_dim=128, n_class=1000, chn=96, blocks_with_attention=\"B4\", resolution=512):\n",
        "        super().__init__()\n",
        "    \n",
        "        def GBlock(in_channel, out_channel, n_class, z_dim, use_attention):\n",
        "            return ResBlock(in_channel, out_channel, n_class=n_class, z_dim=z_dim, use_attention=use_attention)\n",
        "    \n",
        "        self.embed_y = dg.Linear(n_class, 128, bias_attr=False)\n",
        "    \n",
        "        self.chn = chn\n",
        "        self.resolution = resolution \n",
        "        self.blocks_with_attention = set(blocks_with_attention.split(\",\")) \n",
        "        self.blocks_with_attention.discard('')\n",
        "    \n",
        "        gblock = []\n",
        "        in_channels, out_channels = self.get_in_out_channels()\n",
        "        self.num_split = len(in_channels) + 1\n",
        "    \n",
        "        z_dim = code_dim//self.num_split + 128\n",
        "        self.noise_fc = SpectralNorm(dg.Linear(code_dim//self.num_split, 4 * 4 * in_channels[0]))\n",
        "    \n",
        "        self.sa_ids = [int(s.split('B')[-1]) for s in self.blocks_with_attention]\n",
        "    \n",
        "        for i, (nc_in, nc_out) in enumerate(zip(in_channels, out_channels)):\n",
        "            gblock.append(GBlock(nc_in, nc_out, n_class=n_class, z_dim=z_dim, use_attention=(i+1) in self.sa_ids))\n",
        "        self.blocks = dg.LayerList(gblock)\n",
        "    \n",
        "        self.output_layer_bn = BatchNorm(1 * chn, epsilon=1e-5)\n",
        "        self.output_layer_conv = SpectralNorm(dg.Conv2D(1 * chn, 3, [3, 3], padding=1))\n",
        " \n",
        "    def get_in_out_channels(self):\n",
        "        resolution = self.resolution\n",
        "        if resolution == 1024:\n",
        "            channel_multipliers = [16, 16, 8, 8, 4, 2, 1, 1, 1]\n",
        "        elif resolution == 512:\n",
        "            channel_multipliers = [16, 16, 8, 8, 4, 2, 1, 1]\n",
        "        elif resolution == 256:\n",
        "            channel_multipliers = [16, 16, 8, 8, 4, 2, 1]\n",
        "        elif resolution == 128:\n",
        "            channel_multipliers = [16, 16, 8, 4, 2, 1]\n",
        "        elif resolution == 64:\n",
        "            channel_multipliers = [16, 16, 8, 4, 2]\n",
        "        elif resolution == 32:\n",
        "            channel_multipliers = [4, 4, 4, 4]\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported resolution: {}\".format(resolution))\n",
        "        in_channels = [self.chn * c for c in channel_multipliers[:-1]]\n",
        "        out_channels = [self.chn * c for c in channel_multipliers[1:]]\n",
        "        return in_channels, out_channels\n",
        " \n",
        "    def forward(self, input, class_id):\n",
        "        for key, item in gt.items():\n",
        "            item.clear()\n",
        "        gt['z'].append(input)\n",
        "        codes = layers.split(input, self.num_split, 1)\n",
        "        gt['labels'].append(layers.argmax(class_id, 1))\n",
        "        class_emb = self.embed_y(class_id)  # 128\n",
        "        gt['embed_y/MatMul:0'].append(class_emb)\n",
        "        out = self.noise_fc(codes[0])\n",
        "        gt['fc_reshaped:0'].append(layers.reshape(out,(out.shape[0], 4, 4, -1)))\n",
        "        out = layers.transpose(layers.reshape(out,(out.shape[0], 4, 4, -1)),(0, 3, 1, 2))\n",
        "        for i, (code, gblock) in enumerate(zip(codes[1:], self.blocks)):\n",
        "            condition = layers.concat([code, class_emb], 1)\n",
        "            out = gblock(out, condition)\n",
        "    \n",
        "        out = self.output_layer_bn(out)\n",
        "        gt['final_norm/add:0'].append(layers.transpose(out,[0,2,3,1]))\n",
        "        out = layers.relu(out)\n",
        "        out = self.output_layer_conv(out)\n",
        "        gt['final_conv/add:0'].append(layers.transpose(out,[0,2,3,1]))\n",
        "        gt['samples'].append(layers.transpose((layers.tanh(out) + 1) / 2, [0,2,3,1]))\n",
        " \n",
        "        return (layers.tanh(out) + 1) / 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsf2xTVBN-Py"
      },
      "source": [
        "place = fluid.CUDAPlace(fluid.dygraph.ParallelEnv().dev_id)\n",
        "fluid.enable_dygraph(place)\n",
        " \n",
        "g_256 = Generator(code_dim=140, n_class=1000, chn=96, blocks_with_attention=\"B5\", resolution=256)\n",
        "x = layers.randn([4,140])\n",
        "y = layers.randint(0,1000,shape=[4])\n",
        "y_hot = layers.one_hot(layers.unsqueeze(y,[1]), depth=1000)\n",
        "img = g_256(x, y_hot)\n",
        "print(img.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5YodLFu-y63"
      },
      "source": [
        "import pickle\n",
        "f = open('tf_generator.pkl', 'rb')\n",
        "tf_weights = pickle.load(f)\n",
        "f.close()\n",
        " \n",
        "def tf_filter(x):\n",
        "  if 'accu/update_accus:0' in x[0]:\n",
        "    return False\n",
        "  return True\n",
        " \n",
        "tf_weights = filter(tf_filter, tf_weights)\n",
        " \n",
        "def pd_filter(x):\n",
        "  if 'weight_v' in x[0] or '._mean' in x[0] or '._variance' in x[0] \\\n",
        "     or'.bn_in_cond.weight' in x[0] or '.bn_in_cond.bias' in x[0]:\n",
        "    return False\n",
        "  return True\n",
        " \n",
        "_pd_params = list(filter(pd_filter, g_256.named_parameters()))\n",
        "pd_params = []\n",
        "for i, params in enumerate(_pd_params):\n",
        "  b_continue = False\n",
        "  for j in range(6):\n",
        "    if 'attention.gamma' in _pd_params[i-j][0]:\n",
        "      pd_params.append(_pd_params[i+1])\n",
        "      b_continue = True\n",
        "  if b_continue:\n",
        "    continue\n",
        "  if 'attention.gamma' in _pd_params[i-6][0]:\n",
        "    pd_params.append(_pd_params[i-6])\n",
        "    continue\n",
        "  if 'output_layer.0.weight' in params[0]:\n",
        "    pd_params.append(_pd_params[i+1])\n",
        "    continue\n",
        "  if 'output_layer.0.bias' in params[0]:\n",
        "    pd_params.append(_pd_params[i-1])\n",
        "    continue\n",
        "  pd_params.append(params)\n",
        " \n",
        "_pd_params = pd_params\n",
        "pd_params = [param for param in _pd_params]\n",
        "pd_params[-8] = _pd_params[-6]\n",
        "pd_params[-7] = _pd_params[-5]\n",
        "pd_params[-6] = _pd_params[-4]\n",
        "pd_params[-5] = _pd_params[-8]\n",
        "pd_params[-4] = _pd_params[-7]\n",
        " \n",
        "for i, (tf_weight, pd_param) in enumerate(zip(tf_weights, pd_params)):\n",
        "  if len(pd_param[1].shape) == 4:\n",
        "    weight = tf_weight[1].transpose([3, 2, 0, 1])\n",
        "  else:\n",
        "    weight = tf_weight[1].reshape(pd_param[1].shape)\n",
        "  pd_param[1].set_value(weight)\n",
        "  print(tf_weight[0], tf_weight[1].shape, pd_param[0], pd_param[1].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONJui9skEy7b"
      },
      "source": [
        "import pickle\n",
        "f = open('tf_tensor_samples.pkl', 'rb')\n",
        "tf_tensors = pickle.load(f)\n",
        "f.close()\n",
        " \n",
        "gtt = collections.OrderedDict()\n",
        "for n in tensors_name_con:\n",
        "    gtt[n] = []\n",
        "for key, tensor in tf_tensors.items():\n",
        "    for n in tensors_name_con:\n",
        "        if n in key:\n",
        "            gtt[n].append([key, tensor])\n",
        "            break\n",
        " \n",
        "for _layers in g_256.named_sublayers():\n",
        "  class_name = _layers[1].__class__.__name__\n",
        "  if 'BatchNorm' == class_name:\n",
        "    _layers[1].set_initialized(False)\n",
        " \n",
        "g_256.eval()\n",
        "x = dg.to_variable(tf_tensors['z'].astype('float32')) # layers.randn([2,140])\n",
        "y = dg.to_variable(tf_tensors['labels'].astype('int32')) # layers.randint(0,1000,shape=[2])\n",
        "y_hot = layers.one_hot(layers.unsqueeze(y,[1]), depth=1000)\n",
        "img = g_256(x, y_hot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1GEMHaC-zsi"
      },
      "source": [
        "for (_, item1), (key2, item2) in zip(gtt.items(), gt.items()):\n",
        "   for (key1, t1), t2 in zip(item1, item2):\n",
        "       print(key1, key2, t1.shape, t2.shape, (np.abs(t1 - t2.numpy())).mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKVN32si-yPf"
      },
      "source": [
        "img = np.uint8(g_256(x, y_hot).numpy()[0].transpose(1,2,0).clip(0,1)*255)\n",
        "from PIL import Image\n",
        "Image.fromarray(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc1hfTDF_Fdw"
      },
      "source": [
        "save_path = './anime-biggan-256px-run39-607250.generator'\n",
        "dg.save_dygraph(g_256.state_dict(), save_path)\n",
        "!cp ./anime-biggan-256px-run39-607250.generator.pdparams ./drive/My\\ Drive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzKzpLIpc31e"
      },
      "source": [
        "import os\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        " \n",
        "import tensorflow_hub as hub\n",
        " \n",
        "module_path = os.path.join('anime-biggan-256px-run39-607250', \"tfhub\")\n",
        "tf.reset_default_graph()\n",
        "module = hub.Module(module_path)\n",
        "print('Loaded BigGAN module from:', module_path)\n",
        " \n",
        "initializer = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(initializer)\n",
        " \n",
        "batch_size = 4\n",
        "use_ema = True\n",
        "z = tf.random.normal(shape=[batch_size, 140],stddev=1.0,seed=0)  # noise sample\n",
        "labels = tf.random.uniform([batch_size], maxval=1000, dtype=tf.int32, seed=0)\n",
        "inputs = dict(z=z, labels=labels)\n",
        " \n",
        "samples = module(inputs, as_dict=True)['generated']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2Vd3kKtbSlG"
      },
      "source": [
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "[_z, _labels, _samples] = sess.run([z, labels, samples])\n",
        "x = dg.to_variable(_z.astype('float32'))\n",
        "y = dg.to_variable(_labels.astype('int32'))\n",
        "y_hot = layers.one_hot(layers.unsqueeze(y,[1]), depth=1000)\n",
        "img = g_256(x, y_hot)\n",
        "for i in range(4):\n",
        "    img1 = np.uint8(_samples[i].clip(0,1)*255)\n",
        "    img2 = np.uint8(g_256(x, y_hot).numpy()[i].transpose(1,2,0).clip(0,1)*255)\n",
        "    img = np.concatenate([img1, img2], 1)\n",
        "    display(Image.fromarray(img))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}